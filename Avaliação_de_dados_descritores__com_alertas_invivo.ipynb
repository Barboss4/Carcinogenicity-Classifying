{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pi64x_3haQnl"
      },
      "outputs": [],
      "source": [
        "# RDKit\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
        "\n",
        "# Utilitários\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "import joblib\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate,StratifiedGroupKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "\n",
        "# Imports base\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\n",
        "    AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier)\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Modelos externos\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpeza de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Disable informational messages from RDKit\n",
        "RDLogger.DisableLog('rdApp.info')\n",
        "\n",
        "def is_valid_smiles(smiles):\n",
        "    \"\"\"\n",
        "    Checks whether a SMILES string is valid.\n",
        "\n",
        "    Parameters:\n",
        "        smiles (str): The SMILES representation of the molecule.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the SMILES is valid, False otherwise.\n",
        "    \"\"\"\n",
        "    # Return False if SMILES is None, not a string, or empty/whitespace only\n",
        "    if pd.isna(smiles) or not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return False\n",
        "\n",
        "    # Remove leading/trailing spaces\n",
        "    smiles = smiles.strip()\n",
        "\n",
        "    try:\n",
        "        # First, try parsing the SMILES with normal sanitization\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "        if mol is not None:\n",
        "            return True\n",
        "    except Exception:\n",
        "        # Ignore errors here and try without sanitization\n",
        "        pass  \n",
        "\n",
        "    try:\n",
        "        # If normal sanitization fails, parse without sanitization\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            # Attempt manual sanitization and catch possible errors\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # If all parsing attempts fail, return False\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjhoPqaR-0I"
      },
      "source": [
        "# Descritores + Estrutura de alerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nf6TfH3TSB7c"
      },
      "outputs": [],
      "source": [
        "# Disable informational RDKit logs\n",
        "RDLogger.DisableLog('rdApp.info')\n",
        "\n",
        "# Preload RDKit uncharger object for performance\n",
        "_uncharger = rdMolStandardize.Uncharger()\n",
        "\n",
        "# --- Molecule Neutralization ---\n",
        "def neutralize_molecule(mol):\n",
        "    \"\"\"\n",
        "    Neutralizes a molecule using RDKit's standardization tools.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: Neutralized molecule, or original molecule if neutralization fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return None\n",
        "    try:\n",
        "        # Cleanup handles salting, normalization, and common charges\n",
        "        mol = rdMolStandardize.Cleanup(mol)\n",
        "        mol = _uncharger.Uncharge(mol)\n",
        "        return mol\n",
        "    except Exception:\n",
        "        return mol  # Return original molecule if neutralization fails\n",
        "\n",
        "# --- SMILES to Molecule Conversion ---\n",
        "def smiles_to_mol(smiles, neutralize=True):\n",
        "    \"\"\"\n",
        "    Converts a SMILES string to an RDKit molecule object, with optional neutralization.\n",
        "\n",
        "    Parameters:\n",
        "        smiles (str): SMILES string.\n",
        "        neutralize (bool): Whether to neutralize the molecule after parsing.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: RDKit molecule object, or None if parsing fails.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles) or smiles.strip() == \"\":\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "    except Exception:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "\n",
        "    if neutralize:\n",
        "        mol = neutralize_molecule(mol)\n",
        "\n",
        "    return mol\n",
        "\n",
        "# --- Precompiled Descriptor List ---\n",
        "_DESC_FUNCS = [(name, fn) for name, fn in Descriptors.descList]\n",
        "\n",
        "def compute_descriptors(mol):\n",
        "    \"\"\"\n",
        "    Computes molecular descriptors for a given RDKit molecule.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of descriptor names and values, NaN if calculation fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return {f\"desc_{name}\": np.nan for name, _ in _DESC_FUNCS}\n",
        "\n",
        "    out = {}\n",
        "    for name, fn in _DESC_FUNCS:\n",
        "        try:\n",
        "            out[f\"desc_{name}\"] = fn(mol)\n",
        "        except Exception:\n",
        "            out[f\"desc_{name}\"] = np.nan\n",
        "    return out\n",
        "\n",
        "# --- Substructure Search and Descriptor Calculation ---\n",
        "def check_substructures_and_descriptors(\n",
        "    df,\n",
        "    df_structures,\n",
        "    smiles_col='SMILES',\n",
        "    structure_smiles_col='SMILES',\n",
        "    neutralize=True,\n",
        "    use_smarts=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks for the presence of substructures in compounds and computes molecular descriptors.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing compounds with a SMILES column.\n",
        "        df_structures (pd.DataFrame): DataFrame containing substructures (as SMILES or SMARTS).\n",
        "        smiles_col (str): Name of the SMILES column in df.\n",
        "        structure_smiles_col (str): Name of the SMILES/SMARTS column in df_structures.\n",
        "        neutralize (bool): Whether to neutralize compounds before comparison.\n",
        "        use_smarts (bool): If True, interpret df_structures[structure_smiles_col] as SMARTS.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Original DataFrame + descriptor columns (prefix \"desc_\") + binary substructure columns (prefix \"sub_\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Clean column names in the substructure DataFrame\n",
        "    df_structures = df_structures.copy()\n",
        "    df_structures.columns = df_structures.columns.str.strip()\n",
        "\n",
        "    # Prepare substructure patterns\n",
        "    patterns = {}\n",
        "    for pat in df_structures[structure_smiles_col].dropna().astype(str).str.strip().unique():\n",
        "        if pat == \"\":\n",
        "            continue\n",
        "        try:\n",
        "            mol_pat = Chem.MolFromSmarts(pat) if use_smarts else Chem.MolFromSmiles(pat)\n",
        "            if mol_pat is not None:\n",
        "                # Column name for this pattern\n",
        "                colname = f\"sub_{pat}\"\n",
        "                # Avoid overly long column names\n",
        "                if len(colname) > 60:\n",
        "                    colname = f\"sub_{hash(pat)}\"\n",
        "                patterns[colname] = mol_pat\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Prepare storage for results\n",
        "    substructure_results = {col: [] for col in patterns.keys()}\n",
        "    descriptor_results = {f\"desc_{name}\": [] for name, _ in _DESC_FUNCS}\n",
        "\n",
        "    # Process each compound\n",
        "    for smiles in tqdm(df[smiles_col], desc=\"Processing molecules\", unit=\"mol\"):\n",
        "        mol = smiles_to_mol(smiles, neutralize=neutralize)\n",
        "\n",
        "        # Check substructures\n",
        "        for colname, patt in patterns.items():\n",
        "            hit = 0\n",
        "            if mol is not None:\n",
        "                try:\n",
        "                    hit = int(mol.HasSubstructMatch(patt))\n",
        "                except Exception:\n",
        "                    hit = 0\n",
        "            substructure_results[colname].append(hit)\n",
        "\n",
        "        # Compute descriptors\n",
        "        descs = compute_descriptors(mol)\n",
        "        for k in descriptor_results.keys():\n",
        "            descriptor_results[k].append(descs.get(k, np.nan))\n",
        "\n",
        "    # Build DataFrames for substructures and descriptors\n",
        "    df_subs = pd.DataFrame(substructure_results, index=df.index) if substructure_results else pd.DataFrame(index=df.index)\n",
        "    df_descs = pd.DataFrame(descriptor_results, index=df.index)\n",
        "\n",
        "    # Concatenate results with the original DataFrame (keeping index)\n",
        "    df_final = pd.concat([df.reset_index(drop=False), df_descs, df_subs], axis=1)\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2nsvHvoR1kal"
      },
      "outputs": [],
      "source": [
        "df_structures = pd.read_csv('Estruturas de alerta.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9zT2OVSo--1",
        "outputId": "394dcf76-04c7-446a-f63c-aa88f18d61bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19883, 9)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo= pd.read_csv('in vivo + cpdb.csv')\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[22:07:33] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:07:33] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "SMILES_valido",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "count",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "92643887-7dac-4e5c-ab29-885bdddc0067",
              "rows": [
                [
                  "True",
                  "19883"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 1
              }
            },
            "text/plain": [
              "SMILES_valido\n",
              "True    19883\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo['SMILES_valido'] = df_vivo['SMILES'].apply(is_valid_smiles)\n",
        "df_vivo['SMILES_valido'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3617, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop unnecessary columns\n",
        "df_vivo.drop(columns=['Chemical', 'Identificador', 'SMILES_valido','species','strain','Male','Female'], inplace=True)\n",
        "\n",
        "# Convert text columns to lowercase\n",
        "df_vivo['Results'] = df_vivo['Results'].str.lower()\n",
        "df_vivo['Type'] = df_vivo['Type'].str.lower()\n",
        "\n",
        "# Remove duplicate rows if any\n",
        "df_vivo.drop_duplicates(inplace=True)\n",
        "\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de compostos não divergentes: 2227\n",
            "Total de compostos orgânicos: 2090\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 2)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify SMILES (in the filtered DataFrame) that have more than one 'Results' value\n",
        "smiles_multiple_results = df_vivo.groupby(\"SMILES\")[\"Results\"].nunique()\n",
        "smiles_multiple_results = smiles_multiple_results[smiles_multiple_results > 1].index\n",
        "\n",
        "# Remove SMILES that have more than one result\n",
        "df_final_vivo = df_vivo[~df_vivo[\"SMILES\"].isin(smiles_multiple_results)]\n",
        "\n",
        "print(\"Total de compostos não divergentes:\", len(df_final_vivo))\n",
        "\n",
        "df_organicos = df_final_vivo[df_final_vivo[\"SMILES\"].str.contains(r\"C(?![a-z])\", regex=True, na=False)]\n",
        "\n",
        "print(\"Total de compostos orgânicos:\", len(df_organicos))\n",
        "\n",
        "# Drop 'Type' column as it is no longer needed\n",
        "df_final_vivo = df_organicos.drop(columns='Type')\n",
        "\n",
        "# Reset index for clean ordering\n",
        "df_final_vivo.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Show final shape\n",
        "df_final_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iny7HLJEpEWi",
        "outputId": "3cdf91a2-1216-4ee9-a512-68abca83fefe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing molecules: 100%|██████████| 2090/2090 [00:09<00:00, 210.26mol/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 378)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute molecular descriptors and substructure presence for in vivo dataset\n",
        "df_descritores_vivo = check_substructures_and_descriptors(df_final_vivo, df_structures)\n",
        "\n",
        "# Display resulting DataFrame shape\n",
        "df_descritores_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Rodando balanceamento: original ===\n",
            "[OK] Salvo resumo: Resultados/Dest_original.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.811483      0.030025     0.791126    0.033559   \n",
            "1            ExtraTrees       0.814354      0.027328     0.789508    0.031213   \n",
            "2              LightGBM       0.805742      0.030362     0.783626    0.033644   \n",
            "3  HistGradientBoosting       0.804785      0.025197     0.783141    0.027979   \n",
            "4          RandomForest       0.811483      0.020073     0.783685    0.022926   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.740893  0.043536      0.872405     0.022589        0.785810   \n",
            "1  0.737912  0.042106      0.862497     0.020332        0.806591   \n",
            "2  0.730961  0.044679      0.868629     0.019332        0.781584   \n",
            "3  0.730421  0.036519      0.865258     0.021723        0.779411   \n",
            "4  0.729712  0.031589      0.867954     0.015319        0.813739   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.045981     0.702747    0.057285      4.638433     0.155319   \n",
            "1       0.041803     0.681651    0.054882      0.696347     0.098223   \n",
            "2       0.045830     0.687747    0.053454      5.163331     0.212198   \n",
            "3       0.039504     0.689120    0.050706      5.717837     0.034706   \n",
            "4       0.037363     0.662978    0.043517      1.204027     0.122295   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.016027       0.005146  \n",
            "1        0.163097       0.060528  \n",
            "2        0.016949       0.002106  \n",
            "3        0.016352       0.005355  \n",
            "4        0.213258       0.087462  \n",
            "[OK] Salvo folds: Resultados_folds/Dest_original.csv\n",
            "\n",
            "=== Rodando balanceamento: under ===\n",
            "[OK] Salvo resumo: Resultados/Dest_under.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0              LightGBM       0.792344      0.020450     0.789352    0.022745   \n",
            "1            ExtraTrees       0.802871      0.015917     0.790437    0.019206   \n",
            "2              CatBoost       0.792823      0.014970     0.787887    0.016479   \n",
            "3  HistGradientBoosting       0.787560      0.026516     0.785720    0.031064   \n",
            "4               XGBoost       0.787081      0.019952     0.784842    0.020698   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.741716  0.026676      0.860731     0.019873        0.711428   \n",
            "1  0.741398  0.024550      0.859499     0.019283        0.748646   \n",
            "2  0.739648  0.019605      0.859283     0.018093        0.716923   \n",
            "3  0.737150  0.036881      0.862509     0.023235        0.703166   \n",
            "4  0.736578  0.024479      0.863580     0.019458        0.704060   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.026469     0.776204    0.044838      7.318959     0.280435   \n",
            "1       0.028179     0.736343    0.046331      0.593387     0.095780   \n",
            "2       0.026601     0.766235    0.044498     10.704933     3.124950   \n",
            "3       0.031469     0.777485    0.066131      5.325232     0.068424   \n",
            "4       0.030654     0.774923    0.048542      3.947374     0.129082   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.018620       0.001779  \n",
            "1        0.117894       0.022719  \n",
            "2        0.016096       0.002703  \n",
            "3        0.018638       0.006486  \n",
            "4        0.016212       0.006326  \n",
            "[OK] Salvo folds: Resultados_folds/Dest_under.csv\n",
            "\n",
            "=== Rodando balanceamento: over ===\n",
            "[OK] Salvo resumo: Resultados/Dest_over.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0              CatBoost       0.813397      0.021398     0.795532    0.025079   \n",
            "1                 NuSVC       0.808134      0.021569     0.792898    0.021434   \n",
            "2              LightGBM       0.807177      0.025122     0.788268    0.027515   \n",
            "3          RandomForest       0.814354      0.020893     0.789078    0.022954   \n",
            "4  HistGradientBoosting       0.802871      0.023635     0.785303    0.027428   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.746831  0.032554      0.873001     0.019616        0.780954   \n",
            "1  0.744360  0.026318      0.857867     0.025060        0.766082   \n",
            "2  0.737772  0.035217      0.866855     0.016655        0.774389   \n",
            "3  0.737490  0.030967      0.866555     0.018517        0.809828   \n",
            "4  0.733723  0.035851      0.869150     0.015467        0.764501   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.032443     0.717778    0.051766     10.460246     4.068633   \n",
            "1       0.041381     0.726481    0.043350      0.727038     0.201793   \n",
            "2       0.043039     0.706404    0.049945      5.555083     0.201131   \n",
            "3       0.041642     0.679198    0.044764      1.376983     0.173558   \n",
            "4       0.042078     0.708966    0.060574      5.744281     0.085992   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.015608       0.001614  \n",
            "1        0.091058       0.032303  \n",
            "2        0.016878       0.002229  \n",
            "3        0.290852       0.163129  \n",
            "4        0.015368       0.006470  \n",
            "[OK] Salvo folds: Resultados_folds/Dest_over.csv\n",
            "\n",
            "=== Rodando balanceamento: smote ===\n",
            "[OK] Salvo resumo: Resultados/Dest_smote.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0              LightGBM       0.811005      0.025443     0.793548    0.029601   \n",
            "1               XGBoost       0.809091      0.026347     0.793152    0.030690   \n",
            "2              CatBoost       0.806220      0.024527     0.788727    0.025886   \n",
            "3  HistGradientBoosting       0.802871      0.024995     0.788348    0.028554   \n",
            "4          RandomForest       0.809569      0.021493     0.787517    0.023316   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.744264  0.038508      0.866738     0.018172        0.775832   \n",
            "1  0.743938  0.039304      0.870448     0.023673        0.768136   \n",
            "2  0.738723  0.033347      0.869044     0.020517        0.768526   \n",
            "3  0.738296  0.036519      0.866021     0.023106        0.754330   \n",
            "4  0.736180  0.030575      0.867357     0.020359        0.789214   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.039965     0.717685    0.058655      7.361112     0.246711   \n",
            "1       0.039992     0.723889    0.060654      6.322412     0.067129   \n",
            "2       0.041223     0.712731    0.043514     13.390800     5.601297   \n",
            "3       0.036115     0.725170    0.055193      5.862501     0.088671   \n",
            "4       0.039413     0.691651    0.043184      1.327929     0.420301   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.017517       0.002459  \n",
            "1        0.021340       0.007389  \n",
            "2        0.015988       0.003170  \n",
            "3        0.016320       0.004934  \n",
            "4        0.457951       0.395474  \n",
            "[OK] Salvo folds: Resultados_folds/Dest_smote.csv\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# =========================\n",
        "# Model Catalog\n",
        "# =========================\n",
        "model_zoo = {\n",
        "    # Linear regressions / linear classifiers\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "    \"RidgeClassifier\": RidgeClassifier(),\n",
        "    \"SGDClassifier\": SGDClassifier(max_iter=1000, tol=1e-3, n_jobs=-1),\n",
        "    \"PassiveAggressive\": PassiveAggressiveClassifier(max_iter=1000, random_state=42),\n",
        "    \"Perceptron\": Perceptron(max_iter=1000, tol=1e-3, random_state=42),\n",
        "\n",
        "    # Support Vector Machines (SVM)\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"SVC\": SVC(),\n",
        "    \"NuSVC\": NuSVC(),\n",
        "\n",
        "    # Nearest neighbors\n",
        "    \"KNeighbors\": KNeighborsClassifier(),\n",
        "\n",
        "    # Decision trees and tree ensembles\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"ExtraTree\": ExtraTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=42),\n",
        "\n",
        "    # Other ensemble methods\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42, n_jobs=-1),\n",
        "\n",
        "    # Naive Bayes\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"BernoulliNB\": BernoulliNB(),\n",
        "\n",
        "    # Discriminant analysis\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    # Simple neural networks\n",
        "    \"MLPClassifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
        "\n",
        "    # External gradient boosting models\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"LightGBM\": LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=-1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"CatBoost\": CatBoostClassifier(\n",
        "        iterations=500,\n",
        "        learning_rate=0.05,\n",
        "        depth=6,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# BALANCEADORES\n",
        "# =========================\n",
        "balancers = {\n",
        "    \"original\": None,  # sem sampling\n",
        "    \"under\": RandomUnderSampler(random_state=42),\n",
        "    \"over\": RandomOverSampler(random_state=42),\n",
        "    \"smote\": SMOTE(random_state=42),\n",
        "}\n",
        "# =========================\n",
        "# PRÉ-PROCESSAMENTO DO X E y\n",
        "# =========================\n",
        "X = df_descritores_vivo.drop(columns=['SMILES', 'Results']).fillna(0)\n",
        "\n",
        "y = (\n",
        "    df_descritores_vivo['Results']\n",
        "    .astype(str)\n",
        "    .str.lower()\n",
        "    .map({'positive': 1, 'negative': 0})\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# CROSS-VALIDATION E MÉTRICAS\n",
        "# =========================\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
        "    \"f1\": \"f1\",\n",
        "    \"roc_auc\": \"roc_auc\",\n",
        "    \"precision\": \"precision\",\n",
        "    \"recall\": \"recall\",\n",
        "}\n",
        "\n",
        "# garantir pasta\n",
        "import os\n",
        "os.makedirs(\"Resultados\", exist_ok=True)\n",
        "os.makedirs(\"Resultados_folds\", exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOOP PRINCIPAL: sampling → modelos → resultados\n",
        "# =========================\n",
        "for balance_name, sampler in balancers.items():\n",
        "\n",
        "    print(f\"\\n=== Rodando balanceamento: {balance_name} ===\")\n",
        "\n",
        "    pipelines = {}\n",
        "\n",
        "    # Construção dos pipelines\n",
        "    for name, clf in model_zoo.items():\n",
        "\n",
        "        if sampler is None:\n",
        "            pipe = Pipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "        else:\n",
        "            pipe = ImbPipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"sampler\", sampler),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "\n",
        "        pipelines[name] = pipe\n",
        "\n",
        "    # =====================\n",
        "    # 1) MÉDIAS E STD\n",
        "    # =====================\n",
        "    summary_rows = []\n",
        "\n",
        "    # =====================\n",
        "    # 2) VALORES POR FOLD\n",
        "    # =====================\n",
        "    fold_rows = []\n",
        "\n",
        "    for name, pipe in pipelines.items():\n",
        "        cvres = cross_validate(\n",
        "            pipe, X, y,\n",
        "            cv=cv,\n",
        "            scoring=scoring,\n",
        "            n_jobs=-1,\n",
        "            return_train_score=False\n",
        "        )\n",
        "\n",
        "        # ---------- salvar *fold a fold* ----------\n",
        "        for i in range(cv.get_n_splits()):\n",
        "            fold_rows.append({\n",
        "                \"Model\": name,\n",
        "                \"Fold\": i + 1,\n",
        "                \"Accuracy\": cvres[\"test_accuracy\"][i],\n",
        "                \"BalancedAcc\": cvres[\"test_balanced_accuracy\"][i],\n",
        "                \"F1\": cvres[\"test_f1\"][i],\n",
        "                \"ROC_AUC\": cvres[\"test_roc_auc\"][i],\n",
        "                \"Precision\": cvres[\"test_precision\"][i],\n",
        "                \"Recall\": cvres[\"test_recall\"][i],\n",
        "                \"FitTime\": cvres[\"fit_time\"][i],\n",
        "                \"ScoreTime\": cvres[\"score_time\"][i],\n",
        "            })\n",
        "\n",
        "        # ---------- salvar *média e desvio padrão* ----------\n",
        "        summary_rows.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy_mean\": np.mean(cvres[\"test_accuracy\"]),\n",
        "            \"Accuracy_std\":  np.std(cvres[\"test_accuracy\"], ddof=1),\n",
        "            \"BalAcc_mean\":   np.mean(cvres[\"test_balanced_accuracy\"]),\n",
        "            \"BalAcc_std\":    np.std(cvres[\"test_balanced_accuracy\"], ddof=1),\n",
        "            \"F1_mean\":       np.mean(cvres[\"test_f1\"]),\n",
        "            \"F1_std\":        np.std(cvres[\"test_f1\"], ddof=1),\n",
        "            \"ROC_AUC_mean\":  np.mean(cvres[\"test_roc_auc\"]),\n",
        "            \"ROC_AUC_std\":   np.std(cvres[\"test_roc_auc\"], ddof=1),\n",
        "            \"Precision_mean\":np.mean(cvres[\"test_precision\"]),\n",
        "            \"Precision_std\": np.std(cvres[\"test_precision\"], ddof=1),\n",
        "            \"Recall_mean\":   np.mean(cvres[\"test_recall\"]),\n",
        "            \"Recall_std\":    np.std(cvres[\"test_recall\"], ddof=1),\n",
        "            \"FitTime_mean\":  np.mean(cvres[\"fit_time\"]),\n",
        "            \"FitTime_std\":   np.std(cvres[\"fit_time\"], ddof=1),\n",
        "            \"ScoreTime_mean\":np.mean(cvres[\"score_time\"]),\n",
        "            \"ScoreTime_std\": np.std(cvres[\"score_time\"], ddof=1),\n",
        "        })\n",
        "\n",
        "    # ============================\n",
        "    # Salvar RESUMO (médias/std)\n",
        "    # ============================\n",
        "    final_summary = (\n",
        "        pd.DataFrame(summary_rows)\n",
        "        .sort_values(by=\"F1_mean\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    path_summary = f\"Resultados/Dest_{balance_name}.csv\"\n",
        "    final_summary.to_csv(path_summary, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo resumo: {path_summary}\")\n",
        "    print(final_summary.head(5))\n",
        "\n",
        "    # ============================\n",
        "    # Salvar FOLDS (raw)\n",
        "    # ============================\n",
        "    df_folds = pd.DataFrame(fold_rows)\n",
        "    path_folds = f\"Resultados_folds/Dest_{balance_name}.csv\"\n",
        "    df_folds.to_csv(path_folds, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo folds: {path_folds}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
