{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pi64x_3haQnl"
      },
      "outputs": [],
      "source": [
        "# RDKit\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
        "\n",
        "# Utilit√°rios\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "\n",
        "# Imports base\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\n",
        "    AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Modelos externos\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Set Both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Limpeza de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "RDLogger.DisableLog('rdApp.info')   # silencia mensagens informativas\n",
        "\n",
        "def smiles_valido(smiles):\n",
        "    \"\"\"\n",
        "    Verifica se um SMILES √© v√°lido.\n",
        "    \n",
        "    Par√¢metros:\n",
        "        smiles (str): Representa√ß√£o SMILES.\n",
        "    \n",
        "    Retorna:\n",
        "        bool: True se o SMILES √© v√°lido, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles) or not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return False\n",
        "    \n",
        "    smiles = smiles.strip()\n",
        "    \n",
        "    try:\n",
        "        # Primeiro tenta com sanitiza√ß√£o normal\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "        if mol is not None:\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass  # Ignora e tenta de novo sem sanitiza√ß√£o\n",
        "    \n",
        "    try:\n",
        "        # Se falhar, tenta sem sanitiza√ß√£o e sanitiza manualmente\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjhoPqaR-0I"
      },
      "source": [
        "# Descritores + Estrutura de alerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nf6TfH3TSB7c"
      },
      "outputs": [],
      "source": [
        "# Disable informational RDKit logs\n",
        "RDLogger.DisableLog('rdApp.info')\n",
        "\n",
        "# Preload RDKit uncharger object for performance\n",
        "_uncharger = rdMolStandardize.Uncharger()\n",
        "\n",
        "# --- Molecule Neutralization ---\n",
        "def neutralize_molecule(mol):\n",
        "    \"\"\"\n",
        "    Neutralizes a molecule using RDKit's standardization tools.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: Neutralized molecule, or original molecule if neutralization fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return None\n",
        "    try:\n",
        "        # Cleanup handles salting, normalization, and common charges\n",
        "        mol = rdMolStandardize.Cleanup(mol)\n",
        "        mol = _uncharger.Uncharge(mol)\n",
        "        return mol\n",
        "    except Exception:\n",
        "        return mol  # Return original molecule if neutralization fails\n",
        "\n",
        "\n",
        "# --- SMILES to Molecule Conversion ---\n",
        "def smiles_to_mol(smiles, neutralize=True):\n",
        "    \"\"\"\n",
        "    Converts a SMILES string to an RDKit molecule object, with optional neutralization.\n",
        "\n",
        "    Parameters:\n",
        "        smiles (str): SMILES string.\n",
        "        neutralize (bool): Whether to neutralize the molecule after parsing.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: RDKit molecule object, or None if parsing fails.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles) or smiles.strip() == \"\":\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "    except Exception:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "\n",
        "    if neutralize:\n",
        "        mol = neutralize_molecule(mol)\n",
        "\n",
        "    return mol\n",
        "\n",
        "\n",
        "# --- Precompiled Descriptor List ---\n",
        "_DESC_FUNCS = [(name, fn) for name, fn in Descriptors.descList]\n",
        "\n",
        "def compute_descriptors(mol):\n",
        "    \"\"\"\n",
        "    Computes molecular descriptors for a given RDKit molecule.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of descriptor names and values, NaN if calculation fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return {f\"desc_{name}\": np.nan for name, _ in _DESC_FUNCS}\n",
        "\n",
        "    out = {}\n",
        "    for name, fn in _DESC_FUNCS:\n",
        "        try:\n",
        "            out[f\"desc_{name}\"] = fn(mol)\n",
        "        except Exception:\n",
        "            out[f\"desc_{name}\"] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "# --- Descriptor Calculation (RDKit only) ---\n",
        "def compute_rdkit_descriptors(\n",
        "    df,\n",
        "    smiles_col='SMILES',\n",
        "    neutralize=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes RDKit molecular descriptors for a DataFrame containing SMILES.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame contendo uma coluna com SMILES.\n",
        "        smiles_col (str): Nome da coluna de SMILES no DataFrame.\n",
        "        neutralize (bool): Se True, neutraliza as mol√©culas antes de calcular descritores.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame original + colunas de descritores (prefixo \"desc_\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Filtra a lista de descritores para remover os fr_*\n",
        "    _DESC_FUNCS_NO_FR = [(name, fn) for name, fn in _DESC_FUNCS if not name.startswith('fr_')]\n",
        "\n",
        "    # Preparar dicion√°rio de resultados (apenas n√£o-fr)\n",
        "    descriptor_results = {f\"desc_{name}\": [] for name, _ in _DESC_FUNCS_NO_FR}\n",
        "\n",
        "    # Processar cada mol√©cula\n",
        "    for smiles in tqdm(df[smiles_col], desc=\"Calculando descritores\", unit=\"mol\"):\n",
        "        mol = smiles_to_mol(smiles, neutralize=neutralize)\n",
        "\n",
        "        # compute_descriptors pode computar todos; aqui s√≥ puxamos os que mantivemos\n",
        "        descs = compute_descriptors(mol)\n",
        "        for k in descriptor_results.keys():  # k j√° vem como \"desc_<nome>\"\n",
        "            descriptor_results[k].append(descs.get(k, np.nan))\n",
        "\n",
        "    # Criar DataFrame com os descritores\n",
        "    df_descs = pd.DataFrame(descriptor_results, index=df.index)\n",
        "\n",
        "    # Concatenar com o original (mantendo √≠ndice)\n",
        "    df_final = pd.concat([df.reset_index(drop=False), df_descs], axis=1)\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "modelo = \"DeepChem/ChemBERTa-77M-MTR\"\n",
        "\n",
        "# Carregar o tokenizer e o modelo ChemBERTa\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo,trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(modelo, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (3) Fun√ß√£o para obter embedding de um SMILES\n",
        "def get_embedding(smiles):\n",
        "    inputs = tokenizer(smiles, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze()  # Remove batch dimension\n",
        "    return embedding.cpu().numpy()  # Convertendo para numpy array para facilitar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudhqyL_vS_i"
      },
      "source": [
        "# Classifica√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9zT2OVSo--1",
        "outputId": "394dcf76-04c7-446a-f63c-aa88f18d61bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19883, 9)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo= pd.read_csv('in vivo + cpdb.csv')\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[22:13:31] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:13:31] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "SMILES_valido",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "count",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "af71e12d-e7b1-40a7-ac68-54e70f24f0a8",
              "rows": [
                [
                  "True",
                  "19883"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 1
              }
            },
            "text/plain": [
              "SMILES_valido\n",
              "True    19883\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo['SMILES_valido'] = df_vivo['SMILES'].apply(smiles_valido)\n",
        "df_vivo['SMILES_valido'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3617, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop unnecessary columns\n",
        "df_vivo.drop(columns=['Chemical', 'Identificador', 'SMILES_valido','species',\t'strain',\t'Male',\t'Female'], inplace=True)\n",
        "\n",
        "# Convert text columns to lowercase\n",
        "df_vivo['Results'] = df_vivo['Results'].str.lower()\n",
        "df_vivo['Type'] = df_vivo['Type'].str.lower()\n",
        "\n",
        "# Remove duplicate rows if any\n",
        "df_vivo.drop_duplicates(inplace=True)\n",
        "\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de compostos n√£o divergentes: 2227\n",
            "Total de compostos org√¢nicos: 2090\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify SMILES (in the filtered DataFrame) that have more than one 'Results' value\n",
        "smiles_multiple_results = df_vivo.groupby(\"SMILES\")[\"Results\"].nunique()\n",
        "smiles_multiple_results = smiles_multiple_results[smiles_multiple_results > 1].index\n",
        "\n",
        "# Remove SMILES that have more than one result\n",
        "df_final_vivo = df_vivo[~df_vivo[\"SMILES\"].isin(smiles_multiple_results)]\n",
        "\n",
        "print(\"Total de compostos n√£o divergentes:\", len(df_final_vivo))\n",
        "\n",
        "df_organicos = df_final_vivo[df_final_vivo[\"SMILES\"].str.contains(r\"C(?![a-z])\", regex=True, na=False)]\n",
        "\n",
        "print(\"Total de compostos org√¢nicos:\", len(df_organicos))\n",
        "\n",
        "# Drop 'Type' column as it is no longer needed\n",
        "df_final_vivo = df_organicos.drop(columns='Type')\n",
        "\n",
        "# Reset index for clean ordering\n",
        "df_final_vivo.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Show final shape\n",
        "df_final_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iny7HLJEpEWi",
        "outputId": "3cdf91a2-1216-4ee9-a512-68abca83fefe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Calculando descritores: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2090/2090 [00:09<00:00, 221.07mol/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 135)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "df_descritores_vivo = compute_rdkit_descriptors(df_final_vivo)\n",
        "df_descritores_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2090/2090 [00:03<00:00, 651.76it/s]\n"
          ]
        }
      ],
      "source": [
        "smiles_list = df_final_vivo['SMILES'].tolist()\n",
        "len(smiles_list)\n",
        "\n",
        "# Apply the function with a progress bar\n",
        "embeddings = [get_embedding(smiles) for smiles in tqdm(smiles_list, desc=\"Generating embeddings\")]\n",
        "embeddings = pd.DataFrame(np.vstack(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = pd.concat([embeddings.reset_index(drop=True),\n",
        "                      df_descritores_vivo.reset_index(drop=True)], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qFMe8dwHpFZc"
      },
      "outputs": [],
      "source": [
        "X = df_final.drop(columns=['SMILES', 'Results']).fillna(0)\n",
        "X.columns = X.columns.astype(str)   # <- garante que todas s√£o string\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "y = df_final['Results'].astype(str).str.lower().map({'positive':1, 'negative':0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cySPLpCJpGLt",
        "outputId": "28890e69-b74e-4fe0-bd7d-87ee9a607095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Rodando balanceamento: original ===\n",
            "[OK] Salvo resumo: Resultados/Embdesc_original.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.809569      0.016697     0.784689    0.018888   \n",
            "1              LightGBM       0.803828      0.015463     0.780084    0.018790   \n",
            "2         MLPClassifier       0.789474      0.025914     0.771842    0.027319   \n",
            "3  HistGradientBoosting       0.797608      0.019278     0.771746    0.019897   \n",
            "4              CatBoost       0.798565      0.021213     0.771582    0.022104   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.731804  0.025766      0.866730     0.019000        0.799442   \n",
            "1  0.725857  0.025752      0.858434     0.017286        0.785003   \n",
            "2  0.716971  0.034764      0.840946     0.027048        0.745483   \n",
            "3  0.714572  0.027315      0.855568     0.017341        0.783134   \n",
            "4  0.713935  0.029760      0.855218     0.018292        0.789299   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.035409     0.676651    0.041800     29.167352     0.845977   \n",
            "1       0.026945     0.676775    0.043639     27.347060     0.427801   \n",
            "2       0.049166     0.695247    0.061789      4.646808     0.304560   \n",
            "3       0.043718     0.659275    0.039424      9.620287     0.062872   \n",
            "4       0.047589     0.654290    0.043772     45.807666    16.359060   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.022262       0.006893  \n",
            "1        0.021872       0.003896  \n",
            "2        0.009579       0.004690  \n",
            "3        0.021203       0.003859  \n",
            "4        0.020511       0.004633  \n",
            "[OK] Salvo folds: Resultados_folds/Embdesc_original.csv\n",
            "\n",
            "=== Rodando balanceamento: under ===\n",
            "[OK] Salvo resumo: Resultados/Embdesc_under.csv\n",
            "          Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0      LightGBM       0.785646      0.021014     0.781644    0.021860   \n",
            "1  RandomForest       0.790909      0.028086     0.778910    0.025874   \n",
            "2      CatBoost       0.783254      0.025722     0.776834    0.024329   \n",
            "3    ExtraTrees       0.791866      0.022919     0.777756    0.021943   \n",
            "4       XGBoost       0.779904      0.020549     0.774836    0.015700   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.732407  0.026186      0.852708     0.013701        0.706407   \n",
            "1  0.727861  0.031941      0.844165     0.016348        0.733191   \n",
            "2  0.726614  0.028527      0.852760     0.014595        0.708423   \n",
            "3  0.725766  0.027440      0.845179     0.011924        0.738629   \n",
            "4  0.724688  0.018138      0.859074     0.014050        0.702024   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.034489     0.763858    0.054372     29.108360     0.471683   \n",
            "1       0.050535     0.726497    0.050935      3.472224     0.095920   \n",
            "2       0.042177     0.748750    0.045904     36.087421    12.569288   \n",
            "3       0.042599     0.716389    0.045797      0.964910     0.109337   \n",
            "4       0.039196     0.752562    0.043206     27.277380     0.406627   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.020944       0.003352  \n",
            "1        0.138037       0.090107  \n",
            "2        0.021327       0.005325  \n",
            "3        0.167850       0.101890  \n",
            "4        0.026491       0.007617  \n",
            "[OK] Salvo folds: Resultados_folds/Embdesc_under.csv\n",
            "\n",
            "=== Rodando balanceamento: over ===\n",
            "[OK] Salvo resumo: Resultados/Embdesc_over.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.812919      0.018661     0.791643    0.020986   \n",
            "1              LightGBM       0.805263      0.019927     0.782872    0.022567   \n",
            "2                 NuSVC       0.794258      0.021751     0.779024    0.017717   \n",
            "3         MLPClassifier       0.787081      0.023030     0.773380    0.027075   \n",
            "4  HistGradientBoosting       0.795215      0.025096     0.773035    0.024625   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.741570  0.027612      0.865045     0.018389        0.792188   \n",
            "1  0.729777  0.030632      0.856708     0.016782        0.783794   \n",
            "2  0.727565  0.021371      0.854415     0.024023        0.745315   \n",
            "3  0.719874  0.033913      0.837584     0.026834        0.728905   \n",
            "4  0.717735  0.031462      0.855358     0.016689        0.766863   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.036199     0.699105    0.044497     31.843919     0.343728   \n",
            "1       0.038872     0.685432    0.049859     40.329124     0.878396   \n",
            "2       0.045318     0.712747    0.025685      2.194719     0.511788   \n",
            "3       0.033597     0.713904    0.059244      3.472454     0.424726   \n",
            "4       0.049638     0.676636    0.038877     10.178705     0.065692   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.024200       0.007782  \n",
            "1        0.020594       0.003373  \n",
            "2        0.288547       0.151020  \n",
            "3        0.015005       0.005762  \n",
            "4        0.019032       0.005714  \n",
            "[OK] Salvo folds: Resultados_folds/Embdesc_over.csv\n",
            "\n",
            "=== Rodando balanceamento: smote ===\n",
            "[OK] Salvo resumo: Resultados/Embdesc_smote.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.803828      0.022214     0.784486    0.024869   \n",
            "1              CatBoost       0.800478      0.030930     0.781544    0.029482   \n",
            "2  HistGradientBoosting       0.796172      0.027551     0.777776    0.028769   \n",
            "3              LightGBM       0.798086      0.018157     0.777974    0.021009   \n",
            "4                 NuSVC       0.786603      0.022351     0.771890    0.019405   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.732675  0.032509      0.863916     0.016965        0.770297   \n",
            "1  0.729614  0.036848      0.856477     0.018605        0.766708   \n",
            "2  0.724752  0.036103      0.855778     0.019963        0.755112   \n",
            "3  0.724073  0.027875      0.856787     0.015960        0.763966   \n",
            "4  0.718689  0.023498      0.846777     0.023629        0.732179   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.034902     0.700355    0.047518     33.592905     0.421758   \n",
            "1       0.057115     0.699074    0.045753     52.141808    17.826884   \n",
            "2       0.041305     0.697824    0.041762     10.205657     0.054785   \n",
            "3       0.031993     0.690432    0.047710    113.701620     1.397276   \n",
            "4       0.041258     0.707793    0.032471      2.347931     0.495453   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.024771       0.006494  \n",
            "1        0.024001       0.005893  \n",
            "2        0.020573       0.005778  \n",
            "3        0.034990       0.043587  \n",
            "4        0.249160       0.135774  \n",
            "[OK] Salvo folds: Resultados_folds/Embdesc_smote.csv\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# =========================\n",
        "# Model Catalog\n",
        "# =========================\n",
        "model_zoo = {\n",
        "    # Linear regressions / linear classifiers\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "    \"RidgeClassifier\": RidgeClassifier(),\n",
        "    \"SGDClassifier\": SGDClassifier(max_iter=1000, tol=1e-3, n_jobs=-1),\n",
        "    \"PassiveAggressive\": PassiveAggressiveClassifier(max_iter=1000, random_state=42),\n",
        "    \"Perceptron\": Perceptron(max_iter=1000, tol=1e-3, random_state=42),\n",
        "\n",
        "    # Support Vector Machines (SVM)\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"SVC\": SVC(),\n",
        "    \"NuSVC\": NuSVC(),\n",
        "\n",
        "    # Nearest neighbors\n",
        "    \"KNeighbors\": KNeighborsClassifier(),\n",
        "\n",
        "    # Decision trees and tree ensembles\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"ExtraTree\": ExtraTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=42),\n",
        "\n",
        "    # Other ensemble methods\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42, n_jobs=-1),\n",
        "\n",
        "    # Naive Bayes\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"BernoulliNB\": BernoulliNB(),\n",
        "\n",
        "    # Discriminant analysis\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    # Simple neural networks\n",
        "    \"MLPClassifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
        "\n",
        "    # External gradient boosting models\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"LightGBM\": LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=-1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"CatBoost\": CatBoostClassifier(\n",
        "        iterations=500,\n",
        "        learning_rate=0.05,\n",
        "        depth=6,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# BALANCEADORES\n",
        "# =========================\n",
        "balancers = {\n",
        "    \"original\": None,  # sem sampling\n",
        "    \"under\": RandomUnderSampler(random_state=42),\n",
        "    \"over\": RandomOverSampler(random_state=42),\n",
        "    \"smote\": SMOTE(random_state=42),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# PR√â-PROCESSAMENTO DO X E y\n",
        "# =========================\n",
        "X = df_final.drop(columns=['SMILES', 'Results']).fillna(0)\n",
        "\n",
        "# üî• Corre√ß√£o obrigat√≥ria\n",
        "X.columns = X.columns.astype(str)\n",
        "\n",
        "y = (\n",
        "    df_final['Results']\n",
        "    .astype(str)\n",
        "    .str.lower()\n",
        "    .map({'positive': 1, 'negative': 0})\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# CROSS-VALIDATION E M√âTRICAS\n",
        "# =========================\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
        "    \"f1\": \"f1\",\n",
        "    \"roc_auc\": \"roc_auc\",\n",
        "    \"precision\": \"precision\",\n",
        "    \"recall\": \"recall\",\n",
        "}\n",
        "\n",
        "# garantir pasta\n",
        "import os\n",
        "os.makedirs(\"Resultados\", exist_ok=True)\n",
        "os.makedirs(\"Resultados_folds\", exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOOP PRINCIPAL: sampling ‚Üí modelos ‚Üí resultados\n",
        "# =========================\n",
        "for balance_name, sampler in balancers.items():\n",
        "\n",
        "    print(f\"\\n=== Rodando balanceamento: {balance_name} ===\")\n",
        "\n",
        "    pipelines = {}\n",
        "\n",
        "    # Constru√ß√£o dos pipelines\n",
        "    for name, clf in model_zoo.items():\n",
        "\n",
        "        if sampler is None:\n",
        "            pipe = Pipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "        else:\n",
        "            pipe = ImbPipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"sampler\", sampler),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "\n",
        "        pipelines[name] = pipe\n",
        "\n",
        "    # =====================\n",
        "    # 1) M√âDIAS E STD\n",
        "    # =====================\n",
        "    summary_rows = []\n",
        "\n",
        "    # =====================\n",
        "    # 2) VALORES POR FOLD\n",
        "    # =====================\n",
        "    fold_rows = []\n",
        "\n",
        "    for name, pipe in pipelines.items():\n",
        "        cvres = cross_validate(\n",
        "            pipe, X, y,\n",
        "            cv=cv,\n",
        "            scoring=scoring,\n",
        "            n_jobs=-1,\n",
        "            return_train_score=False\n",
        "        )\n",
        "\n",
        "        # ---------- salvar *fold a fold* ----------\n",
        "        for i in range(cv.get_n_splits()):\n",
        "            fold_rows.append({\n",
        "                \"Model\": name,\n",
        "                \"Fold\": i + 1,\n",
        "                \"Accuracy\": cvres[\"test_accuracy\"][i],\n",
        "                \"BalancedAcc\": cvres[\"test_balanced_accuracy\"][i],\n",
        "                \"F1\": cvres[\"test_f1\"][i],\n",
        "                \"ROC_AUC\": cvres[\"test_roc_auc\"][i],\n",
        "                \"Precision\": cvres[\"test_precision\"][i],\n",
        "                \"Recall\": cvres[\"test_recall\"][i],\n",
        "                \"FitTime\": cvres[\"fit_time\"][i],\n",
        "                \"ScoreTime\": cvres[\"score_time\"][i],\n",
        "            })\n",
        "\n",
        "        # ---------- salvar *m√©dia e desvio padr√£o* ----------\n",
        "        summary_rows.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy_mean\": np.mean(cvres[\"test_accuracy\"]),\n",
        "            \"Accuracy_std\":  np.std(cvres[\"test_accuracy\"], ddof=1),\n",
        "            \"BalAcc_mean\":   np.mean(cvres[\"test_balanced_accuracy\"]),\n",
        "            \"BalAcc_std\":    np.std(cvres[\"test_balanced_accuracy\"], ddof=1),\n",
        "            \"F1_mean\":       np.mean(cvres[\"test_f1\"]),\n",
        "            \"F1_std\":        np.std(cvres[\"test_f1\"], ddof=1),\n",
        "            \"ROC_AUC_mean\":  np.mean(cvres[\"test_roc_auc\"]),\n",
        "            \"ROC_AUC_std\":   np.std(cvres[\"test_roc_auc\"], ddof=1),\n",
        "            \"Precision_mean\":np.mean(cvres[\"test_precision\"]),\n",
        "            \"Precision_std\": np.std(cvres[\"test_precision\"], ddof=1),\n",
        "            \"Recall_mean\":   np.mean(cvres[\"test_recall\"]),\n",
        "            \"Recall_std\":    np.std(cvres[\"test_recall\"], ddof=1),\n",
        "            \"FitTime_mean\":  np.mean(cvres[\"fit_time\"]),\n",
        "            \"FitTime_std\":   np.std(cvres[\"fit_time\"], ddof=1),\n",
        "            \"ScoreTime_mean\":np.mean(cvres[\"score_time\"]),\n",
        "            \"ScoreTime_std\": np.std(cvres[\"score_time\"], ddof=1),\n",
        "        })\n",
        "\n",
        "    # ============================\n",
        "    # Salvar RESUMO (m√©dias/std)\n",
        "    # ============================\n",
        "    final_summary = (\n",
        "        pd.DataFrame(summary_rows)\n",
        "        .sort_values(by=\"F1_mean\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    path_summary = f\"Resultados/Embdesc_{balance_name}.csv\"\n",
        "    final_summary.to_csv(path_summary, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo resumo: {path_summary}\")\n",
        "    print(final_summary.head(5))\n",
        "\n",
        "    # ============================\n",
        "    # Salvar FOLDS (raw)\n",
        "    # ============================\n",
        "    df_folds = pd.DataFrame(fold_rows)\n",
        "    path_folds = f\"Resultados_folds/Embdesc_{balance_name}.csv\"\n",
        "    df_folds.to_csv(path_folds, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo folds: {path_folds}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
