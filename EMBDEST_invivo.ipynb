{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pi64x_3haQnl"
      },
      "outputs": [],
      "source": [
        "# RDKit\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
        "\n",
        "# Utilit√°rios\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Transformers\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import NuSVC\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "\n",
        "# Imports base\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier, Perceptron\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier,\n",
        "    AdaBoostClassifier, BaggingClassifier, HistGradientBoostingClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Modelos externos\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Set Both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Limpeza de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "RDLogger.DisableLog('rdApp.info')   # silencia mensagens informativas\n",
        "\n",
        "def smiles_valido(smiles):\n",
        "    \"\"\"\n",
        "    Verifica se um SMILES √© v√°lido.\n",
        "    \n",
        "    Par√¢metros:\n",
        "        smiles (str): Representa√ß√£o SMILES.\n",
        "    \n",
        "    Retorna:\n",
        "        bool: True se o SMILES √© v√°lido, False caso contr√°rio.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles) or not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return False\n",
        "    \n",
        "    smiles = smiles.strip()\n",
        "    \n",
        "    try:\n",
        "        # Primeiro tenta com sanitiza√ß√£o normal\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "        if mol is not None:\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass  # Ignora e tenta de novo sem sanitiza√ß√£o\n",
        "    \n",
        "    try:\n",
        "        # Se falhar, tenta sem sanitiza√ß√£o e sanitiza manualmente\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "            return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjhoPqaR-0I"
      },
      "source": [
        "# Descritores + Estrutura de alerta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nf6TfH3TSB7c"
      },
      "outputs": [],
      "source": [
        "# Disable informational RDKit logs\n",
        "RDLogger.DisableLog('rdApp.info')\n",
        "\n",
        "# Preload RDKit uncharger object for performance\n",
        "_uncharger = rdMolStandardize.Uncharger()\n",
        "\n",
        "# --- Molecule Neutralization ---\n",
        "def neutralize_molecule(mol):\n",
        "    \"\"\"\n",
        "    Neutralizes a molecule using RDKit's standardization tools.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: Neutralized molecule, or original molecule if neutralization fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return None\n",
        "    try:\n",
        "        # Cleanup handles salting, normalization, and common charges\n",
        "        mol = rdMolStandardize.Cleanup(mol)\n",
        "        mol = _uncharger.Uncharge(mol)\n",
        "        return mol\n",
        "    except Exception:\n",
        "        return mol  # Return original molecule if neutralization fails\n",
        "\n",
        "\n",
        "# --- SMILES to Molecule Conversion ---\n",
        "def smiles_to_mol(smiles, neutralize=True):\n",
        "    \"\"\"\n",
        "    Converts a SMILES string to an RDKit molecule object, with optional neutralization.\n",
        "\n",
        "    Parameters:\n",
        "        smiles (str): SMILES string.\n",
        "        neutralize (bool): Whether to neutralize the molecule after parsing.\n",
        "\n",
        "    Returns:\n",
        "        rdkit.Chem.Mol or None: RDKit molecule object, or None if parsing fails.\n",
        "    \"\"\"\n",
        "    if pd.isna(smiles) or smiles.strip() == \"\":\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=True)\n",
        "    except Exception:\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is not None:\n",
        "            Chem.SanitizeMol(mol, catchErrors=True)\n",
        "\n",
        "    if neutralize:\n",
        "        mol = neutralize_molecule(mol)\n",
        "\n",
        "    return mol\n",
        "\n",
        "\n",
        "# --- Precompiled Descriptor List ---\n",
        "_DESC_FUNCS = [(name, fn) for name, fn in Descriptors.descList]\n",
        "\n",
        "def compute_descriptors(mol):\n",
        "    \"\"\"\n",
        "    Computes molecular descriptors for a given RDKit molecule.\n",
        "\n",
        "    Parameters:\n",
        "        mol (rdkit.Chem.Mol): RDKit molecule object.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of descriptor names and values, NaN if calculation fails.\n",
        "    \"\"\"\n",
        "    if mol is None:\n",
        "        return {f\"desc_{name}\": np.nan for name, _ in _DESC_FUNCS}\n",
        "\n",
        "    out = {}\n",
        "    for name, fn in _DESC_FUNCS:\n",
        "        try:\n",
        "            out[f\"desc_{name}\"] = fn(mol)\n",
        "        except Exception:\n",
        "            out[f\"desc_{name}\"] = np.nan\n",
        "    return out\n",
        "\n",
        "\n",
        "# --- Substructure Search and Descriptor Calculation ---\n",
        "def check_substructures_and_descriptors(\n",
        "    df,\n",
        "    df_structures,\n",
        "    smiles_col='SMILES',\n",
        "    structure_smiles_col='SMILES',\n",
        "    neutralize=True,\n",
        "    use_smarts=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks for the presence of substructures in compounds and computes molecular descriptors.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing compounds with a SMILES column.\n",
        "        df_structures (pd.DataFrame): DataFrame containing substructures (as SMILES or SMARTS).\n",
        "        smiles_col (str): Name of the SMILES column in df.\n",
        "        structure_smiles_col (str): Name of the SMILES/SMARTS column in df_structures.\n",
        "        neutralize (bool): Whether to neutralize compounds before comparison.\n",
        "        use_smarts (bool): If True, interpret df_structures[structure_smiles_col] as SMARTS.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Original DataFrame + descriptor columns (prefix \"desc_\") + binary substructure columns (prefix \"sub_\").\n",
        "    \"\"\"\n",
        "\n",
        "    # Clean column names in the substructure DataFrame\n",
        "    df_structures = df_structures.copy()\n",
        "    df_structures.columns = df_structures.columns.str.strip()\n",
        "\n",
        "    # Prepare substructure patterns\n",
        "    patterns = {}\n",
        "    for pat in df_structures[structure_smiles_col].dropna().astype(str).str.strip().unique():\n",
        "        if pat == \"\":\n",
        "            continue\n",
        "        try:\n",
        "            mol_pat = Chem.MolFromSmarts(pat) if use_smarts else Chem.MolFromSmiles(pat)\n",
        "            if mol_pat is not None:\n",
        "                # Column name for this pattern\n",
        "                colname = f\"sub_{pat}\"\n",
        "                # Avoid overly long column names\n",
        "                if len(colname) > 60:\n",
        "                    colname = f\"sub_{hash(pat)}\"\n",
        "                patterns[colname] = mol_pat\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Prepare storage for results\n",
        "    substructure_results = {col: [] for col in patterns.keys()}\n",
        "    descriptor_results = {f\"desc_{name}\": [] for name, _ in _DESC_FUNCS}\n",
        "\n",
        "    # Process each compound\n",
        "    for smiles in tqdm(df[smiles_col], desc=\"Processing molecules\", unit=\"mol\"):\n",
        "        mol = smiles_to_mol(smiles, neutralize=neutralize)\n",
        "\n",
        "        # Check substructures\n",
        "        for colname, patt in patterns.items():\n",
        "            hit = 0\n",
        "            if mol is not None:\n",
        "                try:\n",
        "                    hit = int(mol.HasSubstructMatch(patt))\n",
        "                except Exception:\n",
        "                    hit = 0\n",
        "            substructure_results[colname].append(hit)\n",
        "\n",
        "        # Compute descriptors\n",
        "        descs = compute_descriptors(mol)\n",
        "        for k in descriptor_results.keys():\n",
        "            descriptor_results[k].append(descs.get(k, np.nan))\n",
        "\n",
        "    # Build DataFrames for substructures and descriptors\n",
        "    df_subs = pd.DataFrame(substructure_results, index=df.index) if substructure_results else pd.DataFrame(index=df.index)\n",
        "    df_descs = pd.DataFrame(descriptor_results, index=df.index)\n",
        "\n",
        "    # Concatenate results with the original DataFrame (keeping index)\n",
        "    df_final = pd.concat([df.reset_index(drop=False), df_descs, df_subs], axis=1)\n",
        "\n",
        "    return df_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "modelo = \"DeepChem/ChemBERTa-77M-MTR\"\n",
        "\n",
        "# Carregar o tokenizer e o modelo ChemBERTa\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelo,trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(modelo, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (3) Fun√ß√£o para obter embedding de um SMILES\n",
        "def get_embedding(smiles):\n",
        "    inputs = tokenizer(smiles, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze()  # Remove batch dimension\n",
        "    return embedding.cpu().numpy()  # Convertendo para numpy array para facilitar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OudhqyL_vS_i"
      },
      "source": [
        "# Classifica√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9zT2OVSo--1",
        "outputId": "394dcf76-04c7-446a-f63c-aa88f18d61bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(19883, 9)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo= pd.read_csv('in vivo + cpdb.csv')\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[22:30:43] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:30:43] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "SMILES_valido",
                  "rawType": "bool",
                  "type": "boolean"
                },
                {
                  "name": "count",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "c6753ad6-9b99-460b-8869-d65a4ab39c76",
              "rows": [
                [
                  "True",
                  "19883"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 1
              }
            },
            "text/plain": [
              "SMILES_valido\n",
              "True    19883\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_vivo['SMILES_valido'] = df_vivo['SMILES'].apply(smiles_valido)\n",
        "df_vivo['SMILES_valido'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(19883, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(3617, 3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop unnecessary columns\n",
        "df_vivo.drop(columns=['Chemical', 'Identificador', 'SMILES_valido','species','strain','Male','Female'], inplace=True)\n",
        "\n",
        "# Convert text columns to lowercase\n",
        "df_vivo['Results'] = df_vivo['Results'].str.lower()\n",
        "df_vivo['Type'] = df_vivo['Type'].str.lower()\n",
        "\n",
        "print(df_vivo.shape)\n",
        "\n",
        "# Remove duplicate rows if any\n",
        "df_vivo.drop_duplicates(inplace=True)\n",
        "\n",
        "df_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de compostos n√£o divergentes: 2227\n",
            "Total de compostos org√¢nicos: 2090\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify SMILES (in the filtered DataFrame) that have more than one 'Results' value\n",
        "smiles_multiple_results = df_vivo.groupby(\"SMILES\")[\"Results\"].nunique()\n",
        "smiles_multiple_results = smiles_multiple_results[smiles_multiple_results > 1].index\n",
        "\n",
        "# Remove SMILES that have more than one result\n",
        "df_final_vivo = df_vivo[~df_vivo[\"SMILES\"].isin(smiles_multiple_results)]\n",
        "\n",
        "print(\"Total de compostos n√£o divergentes:\", len(df_final_vivo))\n",
        "\n",
        "df_organicos = df_final_vivo[df_final_vivo[\"SMILES\"].str.contains(r\"C(?![a-z])\", regex=True, na=False)]\n",
        "\n",
        "print(\"Total de compostos org√¢nicos:\", len(df_organicos))\n",
        "\n",
        "# Drop 'Type' column as it is no longer needed\n",
        "df_final_vivo = df_organicos.drop(columns='Type')\n",
        "\n",
        "# Reset index for clean ordering\n",
        "df_final_vivo.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Show final shape\n",
        "df_final_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de SMILES sem carbono: 0\n"
          ]
        }
      ],
      "source": [
        "# garante que a coluna exista\n",
        "assert \"SMILES\" in df_final_vivo.columns, \"Coluna 'SMILES' n√£o encontrada no dataframe\"\n",
        "\n",
        "# conta quantos SMILES n√£o t√™m 'C' (mai√∫sculo)\n",
        "sem_carbono = df_final_vivo[~df_final_vivo[\"SMILES\"].str.contains(\"C\", na=False)]\n",
        "\n",
        "print(\"N√∫mero de SMILES sem carbono:\", len(sem_carbono))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_structures = pd.read_csv('Estruturas de alerta.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iny7HLJEpEWi",
        "outputId": "3cdf91a2-1216-4ee9-a512-68abca83fefe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing molecules: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2090/2090 [00:10<00:00, 204.55mol/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2090, 378)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "df_descritores_vivo = check_substructures_and_descriptors(df_final_vivo, df_structures)\n",
        "df_descritores_vivo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "Results",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "count",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "fd13e403-4fe3-4606-afab-1753d88624be",
              "rows": [
                [
                  "negative",
                  "1286"
                ],
                [
                  "positive",
                  "804"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 2
              }
            },
            "text/plain": [
              "Results\n",
              "negative    1286\n",
              "positive     804\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_descritores_vivo[\"Results\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2090/2090 [00:03<00:00, 664.93it/s]\n"
          ]
        }
      ],
      "source": [
        "smiles_list = df_final_vivo['SMILES'].tolist()\n",
        "len(smiles_list)\n",
        "\n",
        "# Apply the function with a progress bar\n",
        "embeddings = [get_embedding(smiles) for smiles in tqdm(smiles_list, desc=\"Generating embeddings\")]\n",
        "embeddings = pd.DataFrame(np.vstack(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final = pd.concat([embeddings.reset_index(drop=True),\n",
        "                      df_descritores_vivo.reset_index(drop=True)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qFMe8dwHpFZc"
      },
      "outputs": [],
      "source": [
        "X = df_final.drop(columns=['SMILES', 'Results']).fillna(0)\n",
        "X.columns = X.columns.astype(str)   # <- garante que todas s√£o string\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "y = df_final['Results'].astype(str).str.lower().map({'positive':1, 'negative':0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cySPLpCJpGLt",
        "outputId": "28890e69-b74e-4fe0-bd7d-87ee9a607095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Rodando balanceamento: original ===\n",
            "[OK] Salvo resumo: Resultados/Embdest_original.csv\n",
            "           Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0       LightGBM       0.803349      0.017537     0.779197    0.021826   \n",
            "1        XGBoost       0.802871      0.019112     0.777142    0.022687   \n",
            "2       CatBoost       0.804306      0.026635     0.776938    0.029974   \n",
            "3  MLPClassifier       0.790431      0.029564     0.773583    0.032450   \n",
            "4     ExtraTrees       0.807177      0.029499     0.775961    0.032132   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.724406  0.029769      0.859892     0.012313        0.785647   \n",
            "1  0.721442  0.030729      0.865855     0.018496        0.790204   \n",
            "2  0.720457  0.040736      0.860716     0.018664        0.800710   \n",
            "3  0.719349  0.041240      0.838142     0.020254        0.743068   \n",
            "4  0.718402  0.044656      0.853345     0.019772        0.819859   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.029890     0.674213    0.049846     25.084141     0.086675   \n",
            "1       0.032890     0.665463    0.047192     30.885893     0.795537   \n",
            "2       0.050817     0.657994    0.058511     46.324994    14.964972   \n",
            "3       0.047701     0.700309    0.061888      7.003963     0.610175   \n",
            "4       0.053321     0.640525    0.048590      1.142406     0.159922   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.024703       0.003354  \n",
            "1        0.020892       0.005508  \n",
            "2        0.024586       0.004088  \n",
            "3        0.016636       0.008284  \n",
            "4        0.286276       0.134827  \n",
            "[OK] Salvo folds: Resultados_folds/Embdest_original.csv\n",
            "\n",
            "=== Rodando balanceamento: under ===\n",
            "[OK] Salvo resumo: Resultados/Embdest_under.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.786603      0.023353     0.781437    0.024544   \n",
            "1            ExtraTrees       0.797608      0.021165     0.783164    0.027528   \n",
            "2              LightGBM       0.781818      0.024314     0.778047    0.020878   \n",
            "3  HistGradientBoosting       0.781818      0.018763     0.776600    0.018034   \n",
            "4         MLPClassifier       0.774163      0.026090     0.775101    0.030641   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.731914  0.029495      0.862014     0.015793        0.709843   \n",
            "1  0.731376  0.036002      0.850333     0.017873        0.746129   \n",
            "2  0.728747  0.023991      0.854341     0.014025        0.702086   \n",
            "3  0.726469  0.021615      0.856013     0.017820        0.703693   \n",
            "4  0.725397  0.035598      0.834664     0.018817        0.681943   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.035476     0.758781    0.056483     27.696650     0.390458   \n",
            "1       0.029012     0.720247    0.064950      0.939602     0.160775   \n",
            "2       0.042328     0.761327    0.045981    113.933949     1.691740   \n",
            "3       0.034473     0.753781    0.046120     13.333942     0.052707   \n",
            "4       0.034663     0.778750    0.069634      3.733524     0.532744   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.028523       0.006626  \n",
            "1        0.262219       0.131671  \n",
            "2        0.036959       0.033811  \n",
            "3        0.023106       0.004807  \n",
            "4        0.018538       0.006301  \n",
            "[OK] Salvo folds: Resultados_folds/Embdest_under.csv\n",
            "\n",
            "=== Rodando balanceamento: over ===\n",
            "[OK] Salvo resumo: Resultados/Embdest_over.csv\n",
            "           Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0        XGBoost       0.806699      0.017500     0.786800    0.018957   \n",
            "1          NuSVC       0.800000      0.020770     0.783707    0.018260   \n",
            "2            SVC       0.796651      0.023683     0.780055    0.020787   \n",
            "3       LightGBM       0.800957      0.021422     0.779131    0.025350   \n",
            "4  MLPClassifier       0.792823      0.021285     0.777626    0.026352   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.735718  0.024962      0.866551     0.016079        0.777155   \n",
            "1  0.732869  0.022404      0.856617     0.024479        0.757870   \n",
            "2  0.728385  0.024930      0.851985     0.025170        0.753307   \n",
            "3  0.724836  0.034038      0.855106     0.017283        0.774563   \n",
            "4  0.724469  0.033906      0.842496     0.020672        0.741791   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.035550     0.700309    0.039741     33.270829     0.661825   \n",
            "1       0.047548     0.712793    0.040730      4.973664     0.040070   \n",
            "2       0.048240     0.707809    0.035785      4.348229     0.094945   \n",
            "3       0.038501     0.684182    0.056832    137.083110     0.543820   \n",
            "4       0.034460     0.711497    0.063383      5.204334     0.380868   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.038770       0.040604  \n",
            "1        0.507762       0.047394  \n",
            "2        0.579636       0.066268  \n",
            "3        0.024160       0.003146  \n",
            "4        0.019506       0.007092  \n",
            "[OK] Salvo folds: Resultados_folds/Embdest_over.csv\n",
            "\n",
            "=== Rodando balanceamento: smote ===\n",
            "[OK] Salvo resumo: Resultados/Embdest_smote.csv\n",
            "                  Model  Accuracy_mean  Accuracy_std  BalAcc_mean  BalAcc_std  \\\n",
            "0               XGBoost       0.804306      0.022266     0.784864    0.020012   \n",
            "1              CatBoost       0.804306      0.023271     0.784383    0.022362   \n",
            "2                 NuSVC       0.798565      0.024754     0.782547    0.026677   \n",
            "3  HistGradientBoosting       0.800000      0.022869     0.781365    0.022393   \n",
            "4              LightGBM       0.798565      0.019331     0.779506    0.019906   \n",
            "\n",
            "    F1_mean    F1_std  ROC_AUC_mean  ROC_AUC_std  Precision_mean  \\\n",
            "0  0.733830  0.024856      0.865401     0.019493        0.773074   \n",
            "1  0.733035  0.028725      0.861038     0.020121        0.773901   \n",
            "2  0.730982  0.033177      0.851708     0.024375        0.753280   \n",
            "3  0.729254  0.027907      0.860780     0.020323        0.763680   \n",
            "4  0.726713  0.026031      0.858935     0.015933        0.761597   \n",
            "\n",
            "   Precision_std  Recall_mean  Recall_std  FitTime_mean  FitTime_std  \\\n",
            "0       0.046171     0.700324    0.030221     32.651692     0.702509   \n",
            "1       0.045406     0.697824    0.032864     47.571614    12.097499   \n",
            "2       0.041942     0.712793    0.053239      4.594131     0.397775   \n",
            "3       0.044799     0.700309    0.041349     14.789743     0.206437   \n",
            "4       0.038081     0.696620    0.037860     41.327833     1.133605   \n",
            "\n",
            "   ScoreTime_mean  ScoreTime_std  \n",
            "0        0.023209       0.006581  \n",
            "1        0.024417       0.004510  \n",
            "2        0.385011       0.072593  \n",
            "3        0.020433       0.008465  \n",
            "4        0.024810       0.004284  \n",
            "[OK] Salvo folds: Resultados_folds/Embdest_smote.csv\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# =========================\n",
        "# Model Catalog\n",
        "# =========================\n",
        "model_zoo = {\n",
        "    # Linear regressions / linear classifiers\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
        "    \"RidgeClassifier\": RidgeClassifier(),\n",
        "    \"SGDClassifier\": SGDClassifier(max_iter=1000, tol=1e-3, n_jobs=-1),\n",
        "    \"PassiveAggressive\": PassiveAggressiveClassifier(max_iter=1000, random_state=42),\n",
        "    \"Perceptron\": Perceptron(max_iter=1000, tol=1e-3, random_state=42),\n",
        "\n",
        "    # Support Vector Machines (SVM)\n",
        "    \"LinearSVC\": LinearSVC(),\n",
        "    \"SVC\": SVC(),\n",
        "    \"NuSVC\": NuSVC(),\n",
        "\n",
        "    # Nearest neighbors\n",
        "    \"KNeighbors\": KNeighborsClassifier(),\n",
        "\n",
        "    # Decision trees and tree ensembles\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"ExtraTree\": ExtraTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(random_state=42, n_estimators=300, n_jobs=-1),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(random_state=42),\n",
        "\n",
        "    # Other ensemble methods\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"Bagging\": BaggingClassifier(random_state=42, n_jobs=-1),\n",
        "\n",
        "    # Naive Bayes\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"BernoulliNB\": BernoulliNB(),\n",
        "\n",
        "    # Discriminant analysis\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "\n",
        "    # Simple neural networks\n",
        "    \"MLPClassifier\": MLPClassifier(max_iter=1000, random_state=42),\n",
        "\n",
        "    # External gradient boosting models\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"LightGBM\": LGBMClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=-1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"CatBoost\": CatBoostClassifier(\n",
        "        iterations=500,\n",
        "        learning_rate=0.05,\n",
        "        depth=6,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# BALANCEADORES\n",
        "# =========================\n",
        "balancers = {\n",
        "    \"original\": None,  # sem sampling\n",
        "    \"under\": RandomUnderSampler(random_state=42),\n",
        "    \"over\": RandomOverSampler(random_state=42),\n",
        "    \"smote\": SMOTE(random_state=42),\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# PR√â-PROCESSAMENTO DO X E y\n",
        "# =========================\n",
        "X = df_final.drop(columns=['SMILES', 'Results']).fillna(0)\n",
        "\n",
        "# üî• Corre√ß√£o obrigat√≥ria\n",
        "X.columns = X.columns.astype(str)\n",
        "\n",
        "y = (\n",
        "    df_final['Results']\n",
        "    .astype(str)\n",
        "    .str.lower()\n",
        "    .map({'positive': 1, 'negative': 0})\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# CROSS-VALIDATION E M√âTRICAS\n",
        "# =========================\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
        "    \"f1\": \"f1\",\n",
        "    \"roc_auc\": \"roc_auc\",\n",
        "    \"precision\": \"precision\",\n",
        "    \"recall\": \"recall\",\n",
        "}\n",
        "\n",
        "# garantir pasta\n",
        "import os\n",
        "os.makedirs(\"Resultados\", exist_ok=True)\n",
        "os.makedirs(\"Resultados_folds\", exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# LOOP PRINCIPAL: sampling ‚Üí modelos ‚Üí resultados\n",
        "# =========================\n",
        "for balance_name, sampler in balancers.items():\n",
        "\n",
        "    print(f\"\\n=== Rodando balanceamento: {balance_name} ===\")\n",
        "\n",
        "    pipelines = {}\n",
        "\n",
        "    # Constru√ß√£o dos pipelines\n",
        "    for name, clf in model_zoo.items():\n",
        "\n",
        "        if sampler is None:\n",
        "            pipe = Pipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "        else:\n",
        "            pipe = ImbPipeline(steps=[\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"sampler\", sampler),\n",
        "                (\"clf\", clf)\n",
        "            ])\n",
        "\n",
        "        pipelines[name] = pipe\n",
        "\n",
        "    # =====================\n",
        "    # 1) M√âDIAS E STD\n",
        "    # =====================\n",
        "    summary_rows = []\n",
        "\n",
        "    # =====================\n",
        "    # 2) VALORES POR FOLD\n",
        "    # =====================\n",
        "    fold_rows = []\n",
        "\n",
        "    for name, pipe in pipelines.items():\n",
        "        cvres = cross_validate(\n",
        "            pipe, X, y,\n",
        "            cv=cv,\n",
        "            scoring=scoring,\n",
        "            n_jobs=-1,\n",
        "            return_train_score=False\n",
        "        )\n",
        "\n",
        "        # ---------- salvar *fold a fold* ----------\n",
        "        for i in range(cv.get_n_splits()):\n",
        "            fold_rows.append({\n",
        "                \"Model\": name,\n",
        "                \"Fold\": i + 1,\n",
        "                \"Accuracy\": cvres[\"test_accuracy\"][i],\n",
        "                \"BalancedAcc\": cvres[\"test_balanced_accuracy\"][i],\n",
        "                \"F1\": cvres[\"test_f1\"][i],\n",
        "                \"ROC_AUC\": cvres[\"test_roc_auc\"][i],\n",
        "                \"Precision\": cvres[\"test_precision\"][i],\n",
        "                \"Recall\": cvres[\"test_recall\"][i],\n",
        "                \"FitTime\": cvres[\"fit_time\"][i],\n",
        "                \"ScoreTime\": cvres[\"score_time\"][i],\n",
        "            })\n",
        "\n",
        "        # ---------- salvar *m√©dia e desvio padr√£o* ----------\n",
        "        summary_rows.append({\n",
        "            \"Model\": name,\n",
        "            \"Accuracy_mean\": np.mean(cvres[\"test_accuracy\"]),\n",
        "            \"Accuracy_std\":  np.std(cvres[\"test_accuracy\"], ddof=1),\n",
        "            \"BalAcc_mean\":   np.mean(cvres[\"test_balanced_accuracy\"]),\n",
        "            \"BalAcc_std\":    np.std(cvres[\"test_balanced_accuracy\"], ddof=1),\n",
        "            \"F1_mean\":       np.mean(cvres[\"test_f1\"]),\n",
        "            \"F1_std\":        np.std(cvres[\"test_f1\"], ddof=1),\n",
        "            \"ROC_AUC_mean\":  np.mean(cvres[\"test_roc_auc\"]),\n",
        "            \"ROC_AUC_std\":   np.std(cvres[\"test_roc_auc\"], ddof=1),\n",
        "            \"Precision_mean\":np.mean(cvres[\"test_precision\"]),\n",
        "            \"Precision_std\": np.std(cvres[\"test_precision\"], ddof=1),\n",
        "            \"Recall_mean\":   np.mean(cvres[\"test_recall\"]),\n",
        "            \"Recall_std\":    np.std(cvres[\"test_recall\"], ddof=1),\n",
        "            \"FitTime_mean\":  np.mean(cvres[\"fit_time\"]),\n",
        "            \"FitTime_std\":   np.std(cvres[\"fit_time\"], ddof=1),\n",
        "            \"ScoreTime_mean\":np.mean(cvres[\"score_time\"]),\n",
        "            \"ScoreTime_std\": np.std(cvres[\"score_time\"], ddof=1),\n",
        "        })\n",
        "\n",
        "    # ============================\n",
        "    # Salvar RESUMO (m√©dias/std)\n",
        "    # ============================\n",
        "    final_summary = (\n",
        "        pd.DataFrame(summary_rows)\n",
        "        .sort_values(by=\"F1_mean\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    path_summary = f\"Resultados/Embdest_{balance_name}.csv\"\n",
        "    final_summary.to_csv(path_summary, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo resumo: {path_summary}\")\n",
        "    print(final_summary.head(5))\n",
        "\n",
        "    # ============================\n",
        "    # Salvar FOLDS (raw)\n",
        "    # ============================\n",
        "    df_folds = pd.DataFrame(fold_rows)\n",
        "    path_folds = f\"Resultados_folds/Embdest_{balance_name}.csv\"\n",
        "    df_folds.to_csv(path_folds, index=False)\n",
        "\n",
        "    print(f\"[OK] Salvo folds: {path_folds}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
